{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN5O4qPidNEpnfVw6yngX+E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sandeepkumaramgothu/ASE_practice/blob/main/Spect_2_Gun_Other.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KD2oP5HQInoX",
        "outputId": "a2963886-c8a9-48c4-d15a-fdb058c778f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade keras\n",
        "!pip install --upgrade keras tensorflow\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import librosa\n",
        "import json\n",
        "import pandas as pd\n",
        "from termcolor import colored\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "!pip install tensorboard\n",
        "!pip install visualkeras\n",
        "import visualkeras\n",
        "from keras.utils import plot_model\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn import svm\n",
        "from sklearn.svm import SVC\n",
        "import pickle\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from IPython.display import Audio\n",
        "from scipy.io import wavfile\n",
        "import scipy\n",
        "import soundfile as sf\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.metrics import classification_report\n",
        "import random\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUokSGgvIvYY",
        "outputId": "d5e7c91e-6d0a-4d84-fd3d-5a399a716394"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.14.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.14.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras) (24.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.1.24)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.70.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.7)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (4.25.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
            "Requirement already satisfied: visualkeras in /usr/local/lib/python3.11/dist-packages (0.1.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from visualkeras) (11.1.0)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.11/dist-packages (from visualkeras) (1.26.4)\n",
            "Requirement already satisfied: aggdraw>=1.3.11 in /usr/local/lib/python3.11/dist-packages (from visualkeras) (1.3.19)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ljA9M_RYIvcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def create_mel_spectrogram(audio_file, output_dir, sr=16000, n_fft=2048, hop_length=512, n_mels=128):\n",
        "    y, sr = librosa.load(audio_file, sr=sr)\n",
        "    mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
        "    mel_spec_db = librosa.amplitude_to_db(mel_spec, ref=np.max)\n",
        "\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    librosa.display.specshow(mel_spec_db, sr=sr, hop_length=hop_length, x_axis='time', y_axis='mel')\n",
        "    plt.colorbar(format='%+2.0f dB')\n",
        "    plt.title('Mel Spectrogram')\n",
        "    plt.tight_layout()\n",
        "\n",
        "    filename = os.path.basename(audio_file).split('.')[0] + '_mel.png'\n",
        "    save_path = os.path.join(output_dir, filename)\n",
        "    plt.savefig(save_path)\n",
        "    plt.close()\n",
        "\n",
        "    print(f'Mel spectrogram saved as {filename}')\n",
        "\n",
        "def process_directory(audio_dir, output_dir):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    for file in os.listdir(audio_dir):\n",
        "        if file.endswith('.wav') or file.endswith('.mp3'):\n",
        "            audio_file = os.path.join(audio_dir, file)\n",
        "            create_mel_spectrogram(audio_file, output_dir)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Define directories for training and testing audio and mel_images\n",
        "    base_dir = '/content/drive/MyDrive/DataSet/Dataset_Version_2'\n",
        "    categories = ['Train', 'Test']\n",
        "\n",
        "    for category in categories:\n",
        "        audio_dir = os.path.join(base_dir, category, 'Sound')\n",
        "        output_dir = os.path.join(base_dir, category, 'Mel_Images')\n",
        "\n",
        "        if category == 'Train':\n",
        "            # Process only Gun_Shots for training\n",
        "            process_directory(os.path.join(audio_dir, 'Gun_Shots'), os.path.join(output_dir, 'Gun_Shots'))\n",
        "        elif category == 'Test':\n",
        "            # Process Gun_Shots and Other_Sounds for testing\n",
        "            process_directory(os.path.join(audio_dir, 'Gun_Shots'), os.path.join(output_dir, 'Gun_Shots'))\n",
        "            process_directory(os.path.join(audio_dir, 'Other_Sounds'), os.path.join(output_dir, 'Other_Sounds'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZwyIG2KIvfo",
        "outputId": "e743248a-94cf-467f-c8fd-baf577e53a9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mel spectrogram saved as 3 (12)_mel.png\n",
            "Mel spectrogram saved as 3 (16)_mel.png\n",
            "Mel spectrogram saved as 3 (22)_mel.png\n",
            "Mel spectrogram saved as 3 (25)_mel.png\n",
            "Mel spectrogram saved as 3 (11)_mel.png\n",
            "Mel spectrogram saved as 3 (2)_mel.png\n",
            "Mel spectrogram saved as 3 (24)_mel.png\n",
            "Mel spectrogram saved as 3 (10)_mel.png\n",
            "Mel spectrogram saved as 3 (15)_mel.png\n",
            "Mel spectrogram saved as 3 (17)_mel.png\n",
            "Mel spectrogram saved as 3 (23)_mel.png\n",
            "Mel spectrogram saved as 3 (18)_mel.png\n",
            "Mel spectrogram saved as 3 (14)_mel.png\n",
            "Mel spectrogram saved as 3 (26)_mel.png\n",
            "Mel spectrogram saved as 3 (13)_mel.png\n",
            "Mel spectrogram saved as 3 (20)_mel.png\n",
            "Mel spectrogram saved as 3 (19)_mel.png\n",
            "Mel spectrogram saved as 3 (21)_mel.png\n",
            "Mel spectrogram saved as 3 (1)_mel.png\n",
            "Mel spectrogram saved as 3 (29)_mel.png\n",
            "Mel spectrogram saved as 3 (27)_mel.png\n",
            "Mel spectrogram saved as 3 (28)_mel.png\n",
            "Mel spectrogram saved as 3 (30)_mel.png\n",
            "Mel spectrogram saved as 3 (3)_mel.png\n",
            "Mel spectrogram saved as 3 (4)_mel.png\n",
            "Mel spectrogram saved as 3 (5)_mel.png\n",
            "Mel spectrogram saved as 3 (6)_mel.png\n",
            "Mel spectrogram saved as 3 (7)_mel.png\n",
            "Mel spectrogram saved as 3 (8)_mel.png\n",
            "Mel spectrogram saved as 3 (9)_mel.png\n",
            "Mel spectrogram saved as 1 (22)_mel.png\n",
            "Mel spectrogram saved as 1 (11)_mel.png\n",
            "Mel spectrogram saved as 1 (12)_mel.png\n",
            "Mel spectrogram saved as 1 (10)_mel.png\n",
            "Mel spectrogram saved as 1 (3)_mel.png\n",
            "Mel spectrogram saved as 1 (27)_mel.png\n",
            "Mel spectrogram saved as 1 (29)_mel.png\n",
            "Mel spectrogram saved as 1 (1)_mel.png\n",
            "Mel spectrogram saved as 1 (14)_mel.png\n",
            "Mel spectrogram saved as 1 (26)_mel.png\n",
            "Mel spectrogram saved as 1 (18)_mel.png\n",
            "Mel spectrogram saved as 1 (17)_mel.png\n",
            "Mel spectrogram saved as 1 (15)_mel.png\n",
            "Mel spectrogram saved as 1 (2)_mel.png\n",
            "Mel spectrogram saved as 1 (25)_mel.png\n",
            "Mel spectrogram saved as 1 (19)_mel.png\n",
            "Mel spectrogram saved as 1 (20)_mel.png\n",
            "Mel spectrogram saved as 1 (23)_mel.png\n",
            "Mel spectrogram saved as 1 (16)_mel.png\n",
            "Mel spectrogram saved as 1 (13)_mel.png\n",
            "Mel spectrogram saved as 1 (21)_mel.png\n",
            "Mel spectrogram saved as 1 (24)_mel.png\n",
            "Mel spectrogram saved as 1 (28)_mel.png\n",
            "Mel spectrogram saved as 1 (30)_mel.png\n",
            "Mel spectrogram saved as 1 (5)_mel.png\n",
            "Mel spectrogram saved as 1 (4)_mel.png\n",
            "Mel spectrogram saved as 2 (11)_mel.png\n",
            "Mel spectrogram saved as 1 (8)_mel.png\n",
            "Mel spectrogram saved as 2 (14)_mel.png\n",
            "Mel spectrogram saved as 1 (9)_mel.png\n",
            "Mel spectrogram saved as 1 (7)_mel.png\n",
            "Mel spectrogram saved as 1 (6)_mel.png\n",
            "Mel spectrogram saved as 2 (15)_mel.png\n",
            "Mel spectrogram saved as 2 (12)_mel.png\n",
            "Mel spectrogram saved as 2 (13)_mel.png\n",
            "Mel spectrogram saved as 2 (10)_mel.png\n",
            "Mel spectrogram saved as 2 (1)_mel.png\n",
            "Mel spectrogram saved as 2 (25)_mel.png\n",
            "Mel spectrogram saved as 2 (16)_mel.png\n",
            "Mel spectrogram saved as 2 (2)_mel.png\n",
            "Mel spectrogram saved as 2 (20)_mel.png\n",
            "Mel spectrogram saved as 2 (30)_mel.png\n",
            "Mel spectrogram saved as 2 (3)_mel.png\n",
            "Mel spectrogram saved as 2 (17)_mel.png\n",
            "Mel spectrogram saved as 2 (24)_mel.png\n",
            "Mel spectrogram saved as 2 (22)_mel.png\n",
            "Mel spectrogram saved as 2 (28)_mel.png\n",
            "Mel spectrogram saved as 2 (27)_mel.png\n",
            "Mel spectrogram saved as 2 (18)_mel.png\n",
            "Mel spectrogram saved as 2 (21)_mel.png\n",
            "Mel spectrogram saved as 2 (19)_mel.png\n",
            "Mel spectrogram saved as 2 (26)_mel.png\n",
            "Mel spectrogram saved as 2 (29)_mel.png\n",
            "Mel spectrogram saved as 2 (23)_mel.png\n",
            "Mel spectrogram saved as 2 (5)_mel.png\n",
            "Mel spectrogram saved as 2 (6)_mel.png\n",
            "Mel spectrogram saved as 2 (4)_mel.png\n",
            "Mel spectrogram saved as 2 (9)_mel.png\n",
            "Mel spectrogram saved as 2 (8)_mel.png\n",
            "Mel spectrogram saved as 2 (7)_mel.png\n",
            "Mel spectrogram saved as 3 (55)_mel.png\n",
            "Mel spectrogram saved as 3 (52)_mel.png\n",
            "Mel spectrogram saved as 3 (56)_mel.png\n",
            "Mel spectrogram saved as 3 (50)_mel.png\n",
            "Mel spectrogram saved as 3 (51)_mel.png\n",
            "Mel spectrogram saved as 3 (54)_mel.png\n",
            "Mel spectrogram saved as 3 (53)_mel.png\n",
            "Mel spectrogram saved as 3 (59)_mel.png\n",
            "Mel spectrogram saved as 3 (58)_mel.png\n",
            "Mel spectrogram saved as 3 (57)_mel.png\n",
            "Mel spectrogram saved as 3 (60)_mel.png\n",
            "Mel spectrogram saved as 1 (51)_mel.png\n",
            "Mel spectrogram saved as 1 (50)_mel.png\n",
            "Mel spectrogram saved as 1 (53)_mel.png\n",
            "Mel spectrogram saved as 1 (55)_mel.png\n",
            "Mel spectrogram saved as 1 (57)_mel.png\n",
            "Mel spectrogram saved as 1 (52)_mel.png\n",
            "Mel spectrogram saved as 1 (56)_mel.png\n",
            "Mel spectrogram saved as 1 (54)_mel.png\n",
            "Mel spectrogram saved as 1 (60)_mel.png\n",
            "Mel spectrogram saved as 1 (59)_mel.png\n",
            "Mel spectrogram saved as 1 (58)_mel.png\n",
            "Mel spectrogram saved as 2 (59)_mel.png\n",
            "Mel spectrogram saved as 2 (55)_mel.png\n",
            "Mel spectrogram saved as 2 (57)_mel.png\n",
            "Mel spectrogram saved as 2 (50)_mel.png\n",
            "Mel spectrogram saved as 2 (53)_mel.png\n",
            "Mel spectrogram saved as 2 (58)_mel.png\n",
            "Mel spectrogram saved as 2 (54)_mel.png\n",
            "Mel spectrogram saved as 2 (56)_mel.png\n",
            "Mel spectrogram saved as 2 (51)_mel.png\n",
            "Mel spectrogram saved as 2 (60)_mel.png\n",
            "Mel spectrogram saved as 2 (52)_mel.png\n",
            "Mel spectrogram saved as 043210_carstartskidcrashwav-77417_mel.png\n",
            "Mel spectrogram saved as box-crash-106687_mel.png\n",
            "Mel spectrogram saved as ahhh-crash-45495_mel.png\n",
            "Mel spectrogram saved as bang-crash-103775_mel.png\n",
            "Mel spectrogram saved as braking-a-car-in-a-tunnel-153305_mel.png\n",
            "Mel spectrogram saved as 055896_fire-alarm-80450_mel.png\n",
            "Mel spectrogram saved as 080031_fire-alarm-beeping-in-the-morning-80254_mel.png\n",
            "Mel spectrogram saved as alarm-62757_mel.png\n",
            "Mel spectrogram saved as 200805-siren-short-stops-noisy-ms-62576_mel.png\n",
            "Mel spectrogram saved as 027193_heavy-traffic-with-ambulance-sirenwav-74454_mel.png\n",
            "Mel spectrogram saved as a-bomb-139689_mel.png\n",
            "Mel spectrogram saved as blast-mining-77530_mel.png\n",
            "Mel spectrogram saved as bomb-explosion-type-01-265510_mel.png\n",
            "Mel spectrogram saved as 2-blast-explosion-sounds-heavy-bass-246901_mel.png\n",
            "Mel spectrogram saved as big-explosion-41783_mel.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WlIEOBtlIvil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "\n",
        "# Assuming base directory is defined as below from previous code\n",
        "base_dir = '/content/drive/MyDrive/DataSet/Dataset_Version_2/'\n",
        "\n",
        "# Updated directories for the new folder structure\n",
        "train_dir = f'{base_dir}Train/Mel_Images/'\n",
        "test_dir = f'{base_dir}Test/Mel_Images/'\n",
        "\n",
        "\n",
        "height = 128\n",
        "n_fft = 2048\n",
        "hop_length = 512\n",
        "sr = 16000\n",
        "T = 1\n",
        "\n",
        "# Calculating the width from the hop_length and other parameters\n",
        "hop_size_sec = hop_length / sr\n",
        "audio_length_samples = T * sr\n",
        "width = 1 + int((audio_length_samples - n_fft) / hop_length)\n",
        "channels = 3  # Assuming mel spectrograms are stored as RGB images\n",
        "\n",
        "# Setting up the data generators with data augmentation for the training set\n",
        "train_datagen = ImageDataGenerator(\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "# No data augmentation for the test set\n",
        "test_datagen = ImageDataGenerator()\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Creating generators that will feed the CNN\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary')\n",
        "\n",
        "# Define the CNN architecture\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(height, width, channels)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')  # Changed for binary classification\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',  # Changed for binary classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "    model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=len(train_generator),\n",
        "        epochs=1,\n",
        "        verbose=1)\n",
        "\n",
        "# Evaluating the model on the test data\n",
        "loss, accuracy = model.evaluate(test_generator)\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "\n",
        "# Saving the trained model\n",
        "model.save(f'{base_dir}el-amadi_2000_cnn_mcc_standardized.keras')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSuhMj-fIvle",
        "outputId": "7171cec0-5220-403d-9c25-6bc95b000bdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 90 images belonging to 1 classes.\n",
            "Found 48 images belonging to 2 classes.\n",
            "Epoch 1/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2s/step - accuracy: 0.6104 - loss: 8.5283\n",
            "Epoch 2/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 563ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 3/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 558ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 4/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 622ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 5/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 625ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 6/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 570ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 7/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 616ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 8/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 761ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 9/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 529ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 10/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 532ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 11/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 536ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 12/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 895ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 13/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 610ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 14/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 559ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 15/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 558ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 16/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 840ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 17/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 548ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 18/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 532ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 19/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 772ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 20/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 619ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 231ms/step - accuracy: 0.3229 - loss: 1482.8790\n",
            "Test Loss: 1514.2945556640625\n",
            "Test Accuracy: 0.3125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HEtLvnpgIvnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Define paths and model parameters\n",
        "test_directory = '/content/drive/MyDrive/DataSet/Dataset_Version_2/Test/Mel_Images/'\n",
        "model_path = '/content/drive/MyDrive/DataSet/Dataset_Version_2/el-amadi_2000_cnn_mcc_standardized.keras'\n",
        "\n",
        "# Load the pre-trained CNN model\n",
        "model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "# Audio processing parameters\n",
        "sample_rate = 16000\n",
        "fft_points = 2048\n",
        "hop_length = 512\n",
        "audio_duration_seconds = 1\n",
        "\n",
        "# Calculate spectrogram width\n",
        "audio_length_samples = sample_rate * audio_duration_seconds\n",
        "spectrogram_width = 1 + int((audio_length_samples - fft_points) / hop_length)\n",
        "\n",
        "# Image and training parameters\n",
        "image_height = 128\n",
        "image_width = spectrogram_width\n",
        "num_channels = 3\n",
        "batch_size = 32\n",
        "\n",
        "# Setup test data generator\n",
        "test_data_generator = ImageDataGenerator()\n",
        "\n",
        "# Create test generator\n",
        "test_generator = test_data_generator.flow_from_directory(\n",
        "    test_directory,\n",
        "    target_size=(image_height, image_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',  # Assuming binary classification\n",
        "    shuffle=False)\n",
        "\n",
        "# Evaluate the model\n",
        "evaluation_results = model.evaluate(test_generator)\n",
        "print(f\"Test Loss: {evaluation_results[0]}\")\n",
        "print(f\"Test Accuracy: {evaluation_results[1]}\")\n",
        "\n",
        "# Check for additional metrics\n",
        "if len(evaluation_results) > 2:\n",
        "    print(f\"Test Precision: {evaluation_results[2]}\")\n",
        "    print(f\"Test Recall: {evaluation_results[3]}\")\n",
        "    print(f\"Test F1 Score: {evaluation_results[4]}\")\n",
        "\n",
        "# Predict on the test data\n",
        "predictions = model.predict(test_generator)\n",
        "predicted_class_indices = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Retrieve true class labels from the test generator\n",
        "true_class_indices = test_generator.classes\n",
        "\n",
        "# Compute confusion matrix\n",
        "confusion_mat = confusion_matrix(true_class_indices, predicted_class_indices)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_mat)\n",
        "\n",
        "# Retrieve class labels for clarity in reporting\n",
        "class_labels = list(test_generator.class_indices.keys())\n",
        "\n",
        "# Calculate and display accuracy for each class\n",
        "class_accuracy = {}\n",
        "for class_index, class_name in enumerate(class_labels):\n",
        "    correct_class_indices = np.where(true_class_indices == class_index)[0]\n",
        "    correct_predictions = np.sum(predicted_class_indices[correct_class_indices] == class_index)\n",
        "    total_predictions = len(correct_class_indices)\n",
        "    class_accuracy[class_name] = (correct_predictions / total_predictions) if total_predictions > 0 else 0.0\n",
        "\n",
        "print(\"\\nAccuracy for each class:\")\n",
        "for class_name, accuracy in class_accuracy.items():\n",
        "    print(f\"{class_name}: {accuracy:.4f}\")\n",
        "\n",
        "# Print a detailed classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(true_class_indices, predicted_class_indices, target_names=class_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4exfJ4ePhRCy",
        "outputId": "b8ae3339-0b88-49d6-b7d0-e15532df25a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 48 images belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 202ms/step - accuracy: 0.2083 - loss: 1741.7455\n",
            "Test Loss: 1514.2945556640625\n",
            "Test Accuracy: 0.3125\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            "[[33  0]\n",
            " [15  0]]\n",
            "\n",
            "Accuracy for each class:\n",
            "Gun_Shots: 1.0000\n",
            "Other_Sounds: 0.0000\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Gun_Shots       0.69      1.00      0.81        33\n",
            "Other_Sounds       0.00      0.00      0.00        15\n",
            "\n",
            "    accuracy                           0.69        48\n",
            "   macro avg       0.34      0.50      0.41        48\n",
            "weighted avg       0.47      0.69      0.56        48\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "twBoiAbWhRHL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}